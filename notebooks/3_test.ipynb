{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will show some simple examples of featurizing materials composition data using so-called \"composition-based feature vectors\", or CBFVs. This methods represents a single chemical formula as one vector based on its constituent atoms' chemical properties (refer to the paper for more information and references).\n",
    "\n",
    "Note that the steps shown in this notebook are intended to demonstrate the best practices associated with featurizing materials data, using *one* way of featurizing materials composition data as an example. \n",
    "Depending on your input data and your particular modeling needs, the data featurization method and procedure you use may be different than the example shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from CBFV import composition\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Set a random seed to ensure reproducibility across runs\n",
    "RNG_SEED = 42\n",
    "np.random.seed(RNG_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "We will start with the dataset splits that we saved from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train DataFrame shape: (3203, 3)\n",
      "df_val DataFrame shape: (976, 3)\n",
      "df_test DataFrame shape: (368, 3)\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "train_path = os.path.join(PATH, '../data/cp_train.csv')\n",
    "val_path = os.path.join(PATH, '../data/cp_val.csv')\n",
    "test_path = os.path.join(PATH, '../data/cp_test.csv')\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_val = pd.read_csv(val_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "print(f'df_train DataFrame shape: {df_train.shape}')\n",
    "print(f'df_val DataFrame shape: {df_val.shape}')\n",
    "print(f'df_test DataFrame shape: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-sampling your data (optional)\n",
    "\n",
    "If your dataset is too large, you can subsample it to be a smaller size.\n",
    "This is useful for prototyping and for making quick sanity tests of new models / parameters.\n",
    "\n",
    "Just be aware that you do not introduce any bias into your data through the sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_sampled DataFrame shape: (2000, 3)\n",
      "df_val_sampled DataFrame shape: (200, 3)\n",
      "df_test_sampled DataFrame shape:      formula       T       Cp\n",
      "165    I1Li1   600.0   58.660\n",
      "33   Cs2O4S1  1000.0  194.179\n",
      "15       Ba1   900.0   39.066\n",
      "312    O2Si1   298.0   26.581\n",
      "57    Br2Sr1  1400.0  115.060\n",
      "..       ...     ...      ...\n",
      "220    I3Zr1   298.0  103.818\n",
      "342  O4S1Zn1  1800.0  145.185\n",
      "154    I1Li1  1700.0   76.191\n",
      "197    I2Mg1   907.0   87.864\n",
      "351  O4S1Zn1  1013.0  145.185\n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>T</th>\n",
       "      <th>Cp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>O4Pb2Si1</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>197.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>B1H4Na1</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>131.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Fe1H2O2</td>\n",
       "      <td>300.0</td>\n",
       "      <td>97.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>Cs1H1O1</td>\n",
       "      <td>600.0</td>\n",
       "      <td>83.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Fe1I2</td>\n",
       "      <td>600.0</td>\n",
       "      <td>84.425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       formula       T       Cp\n",
       "3008  O4Pb2Si1  1600.0  197.903\n",
       "102    B1H4Na1  1200.0  131.754\n",
       "862    Fe1H2O2   300.0   97.152\n",
       "867    Cs1H1O1   600.0   83.680\n",
       "999      Fe1I2   600.0   84.425"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sub-sample the data. Set the random_state to make the sampling reproducible every time.\n",
    "df_train_sampled = df_train.sample(n=2000, random_state=RNG_SEED)\n",
    "df_val_sampled = df_val.sample(n=200, random_state=RNG_SEED)\n",
    "df_test_sampled = df_test.sample(n=200, random_state=RNG_SEED)\n",
    "\n",
    "print(f'df_train_sampled DataFrame shape: {df_train_sampled.shape}')\n",
    "print(f'df_val_sampled DataFrame shape: {df_val_sampled.shape}')\n",
    "print(f'df_test_sampled DataFrame shape: {df_test_sampled}')\n",
    "df_train_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate features using the `CBFV` package\n",
    "\n",
    "To featurize the chemical compositions from a chemical formula (e.g. \"Al2O3\") into a composition-based feature vector (CBFV), we use the open-source [`CBFV` package](https://pypi.org/project/CBFV/).\n",
    "\n",
    "This package can be pip installed via the command `pip install CBFV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_features` function from the CBFV package expects an input DataFrame containing at least the columns `['formula', 'target']`. You may also have extra feature columns (e.g., `temperature` or `pressure`, other measurement conditions, etc.).\n",
    "\n",
    "In our dataset, `Cp` represents the target variable, and `T` is the measurement condition.\n",
    "Since the `generate_features` function expects the target variable column to be named `target`, we have to rename the `Cp` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame column names before renaming:\n",
      "Index(['formula', 'T', 'Cp'], dtype='object')\n",
      "Index(['formula', 'T', 'Cp'], dtype='object')\n",
      "Index(['formula', 'T', 'Cp'], dtype='object')\n",
      "\n",
      "DataFrame column names after renaming:\n",
      "Index(['formula', 'T', 'target'], dtype='object')\n",
      "Index(['formula', 'T', 'target'], dtype='object')\n",
      "Index(['formula', 'T', 'target'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('DataFrame column names before renaming:')\n",
    "print(df_train.columns)\n",
    "print(df_val.columns)\n",
    "print(df_test.columns)\n",
    "\n",
    "rename_dict = {'Cp': 'target'}\n",
    "df_train = df_train.rename(columns=rename_dict)\n",
    "df_val = df_val.rename(columns=rename_dict)\n",
    "df_test = df_test.rename(columns=rename_dict)\n",
    "\n",
    "df_train_sampled = df_train_sampled.rename(columns=rename_dict)\n",
    "df_val_sampled = df_val_sampled.rename(columns=rename_dict)\n",
    "df_test_sampled = df_test_sampled.rename(columns=rename_dict)\n",
    "\n",
    "print('\\nDataFrame column names after renaming:')\n",
    "print(df_train.columns)\n",
    "print(df_val.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `generate_features` function to generate the CBFVs from the input data.\n",
    "\n",
    "Note that we have specified several keyword arguments in our call to `generate_features`:\n",
    "* `elem_prop='oliynyk'`\n",
    "* `drop_duplicates=False`\n",
    "* `extend_features=True`\n",
    "* `sum_feat=True`\n",
    "\n",
    "A short explanation for the choice of keyword arguments is below:\n",
    "* The `elem_prop` parameter specifies which CBFV featurization scheme to use (there are several). For this tutorial, we have chosen to use the `oliynyk` CBFV featurization scheme.\n",
    "* The `drop_duplicates` parameter specifies whether to drop duplicate formulae during featurization. In our case, we want to preserve duplicate formulae in our data (`True`), since we have multiple heat capacity measurements (performed at different temperatures) for the same compound.\n",
    "* The `extend_features` parameter specifies whether to include extended features (features that are not part of `['formula', 'target']`) in the featurized data. In our case, this is our measurement temperature, and we want to include this information (`True`), since this is pertinent information for the heat capacity prediction.\n",
    "* The `sum_feat` parameter specifies whether to calculate the sum features when generating the CBFVs for the chemical formulae. We do in our case (`True`).\n",
    "\n",
    "For more information about the `generate_features` function and the CBFV featurization scheme, refer to the GitHub repository and the accompanying paper to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|█████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 5725.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|█████████████████████████████████████████████████████| 2000/2000 [00:01<00:00, 1979.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|███████████████████████████████████████████████████████| 200/200 [00:00<00:00, 4084.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|███████████████████████████████████████████████████████| 200/200 [00:00<00:00, 1940.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|███████████████████████████████████████████████████████| 200/200 [00:00<00:00, 3605.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|███████████████████████████████████████████████████████| 200/200 [00:00<00:00, 2408.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    }
   ],
   "source": [
    "X_train_unscaled, y_train, formulae_train, skipped_train = composition.generate_features(df_train_sampled, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_val_unscaled, y_val, formulae_val, skipped_val = composition.generate_features(df_val_sampled, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_test_unscaled, y_test, formulae_test, skipped_test = composition.generate_features(df_test_sampled, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what a featurized X matrix looks like, `.head()` will show us some rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_Atomic_Number</th>\n",
       "      <th>sum_Atomic_Weight</th>\n",
       "      <th>sum_Period</th>\n",
       "      <th>sum_group</th>\n",
       "      <th>sum_families</th>\n",
       "      <th>sum_Metal</th>\n",
       "      <th>sum_Nonmetal</th>\n",
       "      <th>sum_Metalliod</th>\n",
       "      <th>sum_Mendeleev_Number</th>\n",
       "      <th>sum_l_quantum_number</th>\n",
       "      <th>...</th>\n",
       "      <th>mode_Melting_point_(K)</th>\n",
       "      <th>mode_Boiling_Point_(K)</th>\n",
       "      <th>mode_Density_(g/mL)</th>\n",
       "      <th>mode_specific_heat_(J/g_K)_</th>\n",
       "      <th>mode_heat_of_fusion_(kJ/mol)_</th>\n",
       "      <th>mode_heat_of_vaporization_(kJ/mol)_</th>\n",
       "      <th>mode_thermal_conductivity_(W/(m_K))_</th>\n",
       "      <th>mode_heat_atomization(kJ/mol)</th>\n",
       "      <th>mode_Cohesive_energy</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210.0</td>\n",
       "      <td>506.483100</td>\n",
       "      <td>23.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.75</td>\n",
       "      <td>90.15</td>\n",
       "      <td>0.00143</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.22259</td>\n",
       "      <td>3.40990</td>\n",
       "      <td>0.02674</td>\n",
       "      <td>249.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>37.832528</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.05</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>14.304</td>\n",
       "      <td>0.58680</td>\n",
       "      <td>0.44936</td>\n",
       "      <td>0.18150</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.0</td>\n",
       "      <td>89.861680</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.05</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.22259</td>\n",
       "      <td>0.44936</td>\n",
       "      <td>0.02674</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>149.912770</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.05</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.22259</td>\n",
       "      <td>0.44936</td>\n",
       "      <td>0.02674</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>309.655940</td>\n",
       "      <td>14.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>386.65</td>\n",
       "      <td>457.15</td>\n",
       "      <td>4.93000</td>\n",
       "      <td>0.214</td>\n",
       "      <td>7.82400</td>\n",
       "      <td>20.75200</td>\n",
       "      <td>0.44900</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum_Atomic_Number  sum_Atomic_Weight  sum_Period  sum_group  sum_families  \\\n",
       "0              210.0         506.483100        23.0      106.0          44.0   \n",
       "1               20.0          37.832528         9.0       18.0          35.0   \n",
       "2               44.0          89.861680        10.0       42.0          32.0   \n",
       "3               64.0         149.912770         9.0       18.0          15.0   \n",
       "4              132.0         309.655940        14.0       42.0          20.0   \n",
       "\n",
       "   sum_Metal  sum_Nonmetal  sum_Metalliod  sum_Mendeleev_Number  \\\n",
       "0        2.0           5.0            0.0                 588.0   \n",
       "1        1.0           4.0            1.0                 442.0   \n",
       "2        1.0           4.0            0.0                 413.0   \n",
       "3        1.0           2.0            0.0                 184.0   \n",
       "4        1.0           2.0            0.0                 247.0   \n",
       "\n",
       "   sum_l_quantum_number  ...  mode_Melting_point_(K)  mode_Boiling_Point_(K)  \\\n",
       "0                   7.0  ...                   54.75                   90.15   \n",
       "1                   1.0  ...                   14.05                   20.25   \n",
       "2                   4.0  ...                   14.05                   20.25   \n",
       "3                   1.0  ...                   14.05                   20.25   \n",
       "4                   4.0  ...                  386.65                  457.15   \n",
       "\n",
       "   mode_Density_(g/mL)  mode_specific_heat_(J/g_K)_  \\\n",
       "0              0.00143                        0.920   \n",
       "1              0.00007                       14.304   \n",
       "2              0.00007                        0.920   \n",
       "3              0.00007                        0.240   \n",
       "4              4.93000                        0.214   \n",
       "\n",
       "   mode_heat_of_fusion_(kJ/mol)_  mode_heat_of_vaporization_(kJ/mol)_  \\\n",
       "0                        0.22259                              3.40990   \n",
       "1                        0.58680                              0.44936   \n",
       "2                        0.22259                              0.44936   \n",
       "3                        0.22259                              0.44936   \n",
       "4                        7.82400                             20.75200   \n",
       "\n",
       "   mode_thermal_conductivity_(W/(m_K))_  mode_heat_atomization(kJ/mol)  \\\n",
       "0                               0.02674                          249.0   \n",
       "1                               0.18150                          218.0   \n",
       "2                               0.02674                          218.0   \n",
       "3                               0.02674                           79.0   \n",
       "4                               0.44900                          107.0   \n",
       "\n",
       "   mode_Cohesive_energy       T  \n",
       "0                  2.62  1600.0  \n",
       "1                  0.00  1200.0  \n",
       "2                  0.00   300.0  \n",
       "3                  0.00   600.0  \n",
       "4                  1.11   600.0  \n",
       "\n",
       "[5 rows x 309 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unscaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 309)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unscaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `sum` features in the CBFV, which we have included by using `sum_feat=True` in the call to `generate_features`.\n",
    "\n",
    "Also note the temperature column `T` at the end of this featurized data.\n",
    "\n",
    "What we have done above is featurize the input data. In the featurized data, each row contains a unique CBFV that describes a given chemical composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scaling & normalization\n",
    "\n",
    "For numerical input data, scaling and normalization of the features often improves the model performance.\n",
    "Scaling can partially correct the discrepancy between the orders of magnitudes of the features (e.g., some numerical features being much larger or smaller than others).\n",
    "This typically improves the model learning performance, and in turn, improves the model performance.\n",
    "\n",
    "We will scale then normalize our input data using scikit-learn's built-in `StandardScaler` class and `normalize` function.\n",
    "\n",
    "Note, in addition to `StandardScaler`, other scalers such as `RobustScaler` and `MinMaxScaler` are also available in scikit-learn. Consult the documentation for the details and when to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data\n",
    "\n",
    "First, we instantiate the scaler object.\n",
    "\n",
    "In a `StandardScaler` object:\n",
    "* During the `fit` process, the statistics of the input data (mean and standard deviation) are computed.\n",
    "* Then, during the `transform` process, the mean and standard deviation values calculated above are used to scale the data to having zero-mean and unit variance.\n",
    "\n",
    "Therefore, for the first time usage of the scaler, we call the `.fit_transform()` method to fit the scaler to the input data, and then to transform the same data.\n",
    "For subsequent uses, since we have already computed the statistics, we only call the `.transform()` method to scale data.\n",
    "\n",
    "**Note:** you should *only* `.fit()` the scaler using the training dataset statistics, and then use these same statistics from the training dataset to `.transform()` the other datasets (validation and train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_unscaled)\n",
    "X_val = scaler.transform(X_val_unscaled)\n",
    "X_test = scaler.transform(X_test_unscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the scaled data\n",
    "\n",
    "We repeat a similar process for normalizing the data.\n",
    "Here, there is no need to first fit the normalizer, since the normalizer scales the rows of the input data to unit norm independently of other rows.\n",
    "\n",
    "The normalizer is different to a Scaler in that the normalizer acts row-wise, whereas a Scaler acts column-wise on the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize(X_train)\n",
    "X_val = normalize(X_val)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our first model!\n",
    "\n",
    "Now that our data is ready to go, we can show you just how simple it is to train a model and make a prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute '_validate_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m AdaBoostRegressor\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     13\u001b[0m formula_to_predict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformula\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSr1Al2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBa1Cl2\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m950\u001b[39m],\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m16\u001b[39m]}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bestpractices2\\lib\\site-packages\\sklearn\\base.py:1145\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1141\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1142\u001b[0m )\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1145\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute '_validate_params'"
     ]
    }
   ],
   "source": [
    "#let's grab a simple linear model from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "model = AdaBoostRegressor\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "formula_to_predict = {'formula': ['Sr1Al2', 'Ba1Cl2'],\n",
    "        'T': [400, 950],\n",
    "        'target': [13, 16]}\n",
    "\n",
    "df = pd.DataFrame(formula_to_predict)\n",
    "X_to_predict, y_to_predict, formulae_train, skipped_train = composition.generate_features(df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_to_predict = scaler.transform(X_to_predict)\n",
    "X_to_predict = normalize(X_to_predict)\n",
    "\n",
    "predictions = model.predict(X_to_predict)\n",
    "print(\"Predicted heat capacities:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling using \"classical\" machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we implement some classical ML models from `sklearn`:\n",
    "\n",
    "* Ridge regression\n",
    "* Support vector machine\n",
    "* Linear support vector machine\n",
    "* Random forest\n",
    "* Extra trees\n",
    "* Adaptive boosting\n",
    "* Gradient boosting\n",
    "* k-nearest neighbors\n",
    "* Dummy (if you can't beat this, something is wrong.)\n",
    "\n",
    "Note: the Dummy model types from `sklearn` act as a good sanity check for your ML studies. If your models do not perform significantly better than the equivalent Dummy models, then you should know that something has gone wrong in your model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_model(model_name):\n",
    "    model = model_name()\n",
    "    return model\n",
    "\n",
    "def fit_model(model, X_train, y_train):\n",
    "    ti = time()\n",
    "    model = instantiate_model(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    fit_time = time() - ti\n",
    "    return model, fit_time\n",
    "\n",
    "def evaluate_model(model, X, y_act):\n",
    "    y_pred = model.predict(X)\n",
    "    r2 = r2_score(y_act, y_pred)\n",
    "    mae = mean_absolute_error(y_act, y_pred)\n",
    "    rmse_val = mean_squared_error(y_act, y_pred, squared=False)\n",
    "    return r2, mae, rmse_val\n",
    "\n",
    "def fit_evaluate_model(model, model_name, X_train, y_train, X_val, y_act_val):\n",
    "    model, fit_time = fit_model(model, X_train, y_train)\n",
    "    r2_train, mae_train, rmse_train = evaluate_model(model, X_train, y_train)\n",
    "    r2_val, mae_val, rmse_val = evaluate_model(model, X_val, y_act_val)\n",
    "    result_dict = {\n",
    "        'model_name': model_name,\n",
    "        'model_name_pretty': type(model).__name__,\n",
    "        'model_params': model.get_params(),\n",
    "        'fit_time': fit_time,\n",
    "        'r2_train': r2_train,\n",
    "        'mae_train': mae_train,\n",
    "        'rmse_train': rmse_train,\n",
    "        'r2_val': r2_val,\n",
    "        'mae_val': mae_val,\n",
    "        'rmse_val': rmse_val}\n",
    "    return model, result_dict\n",
    "\n",
    "def append_result_df(my_df, result_dict):\n",
    "    df_result_appended = pd.DataFrame(result_dict, index=[0])\n",
    "    my_df = pd.concat([my_df, df_result_appended], ignore_index=True)\n",
    "    return my_df\n",
    "\n",
    "\n",
    "def append_model_dict(dic, model_name, model):\n",
    "    dic[model_name] = model\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an empty DataFrame to store model results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_name_pretty</th>\n",
       "      <th>model_params</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r2_val</th>\n",
       "      <th>mae_val</th>\n",
       "      <th>rmse_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_name, model_name_pretty, model_params, fit_time, r2_train, mae_train, rmse_train, r2_val, mae_val, rmse_val]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classics = pd.DataFrame(columns=['model_name',\n",
    "                                    'model_name_pretty',\n",
    "                                    'model_params',\n",
    "                                    'fit_time',\n",
    "                                    'r2_train',\n",
    "                                    'mae_train',\n",
    "                                    'rmse_train',\n",
    "                                    'r2_val',\n",
    "                                    'mae_val',\n",
    "                                    'rmse_val'])\n",
    "df_classics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the models\n",
    "\n",
    "Here, we instantiate several classical machine learning models for use.\n",
    "For demonstration purposes, we instantiate the models with their default model parameters.\n",
    "\n",
    "Some of the models listed above can perform either regression or classification tasks.\n",
    "Because our ML task is a regression task (prediction of the continuous-valued target, heat capacity), we choose the regression variant of these models.\n",
    "\n",
    "Note: the `DummyRegressor()` instance acts as a good sanity check for your ML studies. If your models do not perform significantly better than the `DummyRegressor()`, then you know something has gone awry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary of model names\n",
    "classic_model_names = OrderedDict({\n",
    "    'dumr': DummyRegressor,\n",
    "    'rr': Ridge,\n",
    "    'abr': AdaBoostRegressor,\n",
    "    'gbr': GradientBoostingRegressor,\n",
    "    'rfr': RandomForestRegressor,\n",
    "    'etr': ExtraTreesRegressor,\n",
    "    'svr': SVR,\n",
    "    'lsvr': LinearSVR,\n",
    "    'knr': KNeighborsRegressor,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and fit the models\n",
    "\n",
    "Now, we can fit the ML models.\n",
    "\n",
    "We will loop through each of the models listed above. For each of the models, we will:\n",
    "* instantiate the model (with default parameters)\n",
    "* fit the model using the training data\n",
    "* use the fitted model to generate predictions from the validation data\n",
    "* evaluate the performance of the model using the predictions\n",
    "* store the results in a DataFrame for analysis\n",
    "\n",
    "Note: this may take several minutes, depending on your hardware/software environment, dataset size and featurization scheme (CBFV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now fitting and evaluating model dumr: DummyRegressor\n",
      "Now fitting and evaluating model rr: Ridge\n",
      "Now fitting and evaluating model abr: AdaBoostRegressor\n",
      "Now fitting and evaluating model gbr: GradientBoostingRegressor\n",
      "Now fitting and evaluating model rfr: RandomForestRegressor\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m classic_model_names\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNow fitting and evaluating model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     model, result_dict \u001b[38;5;241m=\u001b[39m \u001b[43mfit_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     df_classics \u001b[38;5;241m=\u001b[39m append_result_df(df_classics, result_dict)\n\u001b[0;32m     12\u001b[0m     classic_models \u001b[38;5;241m=\u001b[39m append_model_dict(classic_models, model_name, model)\n",
      "Cell \u001b[1;32mIn[13], line 20\u001b[0m, in \u001b[0;36mfit_evaluate_model\u001b[1;34m(model, model_name, X_train, y_train, X_val, y_act_val)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_evaluate_model\u001b[39m(model, model_name, X_train, y_train, X_val, y_act_val):\n\u001b[1;32m---> 20\u001b[0m     model, fit_time \u001b[38;5;241m=\u001b[39m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     r2_train, mae_train, rmse_train \u001b[38;5;241m=\u001b[39m evaluate_model(model, X_train, y_train)\n\u001b[0;32m     22\u001b[0m     r2_val, mae_val, rmse_val \u001b[38;5;241m=\u001b[39m evaluate_model(model, X_val, y_act_val)\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36mfit_model\u001b[1;34m(model, X_train, y_train)\u001b[0m\n\u001b[0;32m      6\u001b[0m ti \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m instantiate_model(model)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m ti\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, fit_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bestpractices2\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bestpractices2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bestpractices2\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bestpractices2\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bestpractices2\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bestpractices2\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bestpractices2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bestpractices2\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bestpractices2\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bestpractices2\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate a dictionary to store the model objects\n",
    "classic_models = OrderedDict()\n",
    "\n",
    "# Keep track of elapsed time\n",
    "ti = time()\n",
    "\n",
    "# Loop through each model type, fit and predict, and evaluate and store results\n",
    "for model_name, model in classic_model_names.items():\n",
    "    print(f'Now fitting and evaluating model {model_name}: {model.__name__}')\n",
    "    model, result_dict = fit_evaluate_model(model, model_name, X_train, y_train, X_val, y_val)\n",
    "    df_classics = append_result_df(df_classics, result_dict)\n",
    "    classic_models = append_model_dict(classic_models, model_name, model)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished fitting {len(classic_models)} models, total time: {dt:0.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can look at the results.\n",
    "\n",
    "You will notice, that some of the models (such as RandomForestRegressor, ExtraTreesRegressor and GradientBoostingRegressor) have completely memorized the training data, as evidenced by the very high r2_train scores of ~1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort in order of increasing validation r2 score\n",
    "df_classics = df_classics.sort_values('r2_val', ignore_index=True)\n",
    "df_classics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now also access the full details of the models by inspecting the `classic_models` dictionary that we populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model performance on validation dataset\n",
    "\n",
    "Now comes the time to evaluate the trained models on the validation set.\n",
    "\n",
    "Remember, we use the same validation set to evaluate all models. This ensures a fair comparison.\n",
    "\n",
    "In addition, we plot the predicted vs. actual plots using the predictions made by each trained model on the same validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_act(act, pred, model, reg_line=True, label=''):\n",
    "    xy_max = np.max([np.max(act), np.max(pred)])\n",
    "\n",
    "    plot = plt.figure(figsize=(6,6))\n",
    "    plt.plot(act, pred, 'o', ms=9, mec='k', mfc='silver', alpha=0.4)\n",
    "    plt.plot([0, xy_max], [0, xy_max], 'k--', label='ideal')\n",
    "    if reg_line:\n",
    "        polyfit = np.polyfit(act, pred, deg=1)\n",
    "        reg_ys = np.poly1d(polyfit)(np.unique(act))\n",
    "        plt.plot(np.unique(act), reg_ys, alpha=0.8, label='linear fit')\n",
    "    plt.axis('scaled')\n",
    "    plt.xlabel(f'Actual {label}')\n",
    "    plt.ylabel(f'Predicted {label}')\n",
    "    plt.title(f'{type(model).__name__}, r2: {r2_score(act, pred):0.4f}')\n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(df_classics.shape[0]):\n",
    "    model_name = df_classics.iloc[row]['model_name']\n",
    "\n",
    "    model = classic_models[model_name]\n",
    "    y_act_val = y_val\n",
    "    y_pred_val = model.predict(X_val)\n",
    "\n",
    "    plot = plot_pred_act(y_act_val, y_pred_val, model, reg_line=True, label='$\\mathrm{C}_\\mathrm{p}$ (J / mol K)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-training the best-performing model on combined train + validation dataset\n",
    "\n",
    "After you have finalized your model, you can re-train your model (using the same hyperparameters) again on the combined train + validation datasets, and finally, evaluate your model on the held-out test dataset.\n",
    "\n",
    "By training on the combined train + validation dataset after you have finished tuning your model, you give it more training data, which should lead to an increase in the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best-performing model that we have tested\n",
    "best_row = df_classics.iloc[-1, :].copy()\n",
    "\n",
    "# Get the model type and model parameters\n",
    "model_name = best_row['model_name']\n",
    "model_params = best_row['model_params']\n",
    "\n",
    "# Instantiate the model again using the parameters\n",
    "model = classic_model_names[model_name](**model_params)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the train and validation datasets together\n",
    "X_train_new = np.concatenate((X_train, X_val), axis=0)\n",
    "y_train_new = pd.concat((y_train, y_val), axis=0)\n",
    "\n",
    "print(X_train_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can fit the model on the combined train + validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = time()\n",
    "\n",
    "model.fit(X_train_new, y_train_new)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished fitting best model, total time: {dt:0.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the re-trained model on the test dataset\n",
    "\n",
    "After re-fitting the best model on the train+validation dataset, you can finally test it on the test dataset.\n",
    "**Remember:** you should only do this *once!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_act_test = y_test\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "r2, mae, rmse = evaluate_model(model, X_test, y_test)\n",
    "print(f'r2: {r2:0.4f}')\n",
    "print(f'mae: {mae:0.4f}')\n",
    "print(f'rmse: {rmse:0.4f}')\n",
    "\n",
    "plot = plot_pred_act(y_act_test, y_pred_test, model, reg_line=True, label='$\\mathrm{C}_\\mathrm{p}$ (J / mol K)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our model achieves decent performance on the held-out test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of train/validation/test dataset split\n",
    "\n",
    "Using different train/validation/test splits can dramatically affect your model performance, even for classical ML models.\n",
    "\n",
    "Here, we provide a little demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unscaled, y_train, formulae_train, skipped_train = generate_features(df_train, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_val_unscaled, y_val, formulae_val, skipped_val = generate_features(df_val, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_test_unscaled, y_test, formulae_test, skipped_test = generate_features(df_test, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = X_train_unscaled.copy()\n",
    "X_val = X_val_unscaled.copy()\n",
    "X_test = X_test_unscaled.copy()\n",
    "\n",
    "y_train_original = y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample the training data using 10 random seeds, by using the `DataFrame.sample()` method with seeds ranging from 0 to 9.\n",
    "We then fit 10 models, each on one of the random splits, and evaluate their performance on the same validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = range(10)\n",
    "df_splits = pd.DataFrame(columns=['split',\n",
    "                                  'r2_train',\n",
    "                                  'mae_train',\n",
    "                                  'rmse_train',\n",
    "                                  'r2_val',\n",
    "                                  'mae_val',\n",
    "                                  'rmse_val'])\n",
    "\n",
    "for split in splits:\n",
    "    print(f'Fitting and evaluating random split {split}')\n",
    "    X_train = X_train_original.sample(frac=0.7, random_state=split)\n",
    "    y_train = y_train_original[X_train.index]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = normalize(scaler.fit_transform(X_train))\n",
    "    X_val = normalize(scaler.transform(X_val_unscaled))\n",
    "    X_test = normalize(scaler.transform(X_test_unscaled))\n",
    "    \n",
    "    model = AdaBoostRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_act_val = y_val\n",
    "    y_pred_val = model.predict(X_val)\n",
    "\n",
    "    r2_train, mae_train, rmse_train = evaluate_model(model, X_train, y_train)\n",
    "    r2_val, mae_val, rmse_val = evaluate_model(model, X_val, y_val)\n",
    "    result_dict = {\n",
    "        'split': split,\n",
    "        'r2_train': r2_train,\n",
    "        'mae_train': mae_train,\n",
    "        'rmse_train': rmse_train,\n",
    "        'r2_val': r2_val,\n",
    "        'mae_val': mae_val,\n",
    "        'rmse_val': rmse_val}\n",
    "    \n",
    "    df_splits = append_result_df(df_splits, result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splits['split'] = df_splits['split'].astype(int)\n",
    "df_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot the train and validation $r^2$ scores for each of the 10 models.\n",
    "\n",
    "Note the high variability in the r2_val score. In contrast, the variability in the r2_train score is comparatively lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splits.plot('split', ['r2_train', 'r2_val'], kind='bar')\n",
    "plt.title(f'Performance of {type(model).__name__}\\nwith {len(splits)} different data splits')\n",
    "plt.ylim((0.5, 1.0))\n",
    "plt.ylabel('$r^2$')\n",
    "plt.xlabel('Split #')\n",
    "plt.legend(loc='lower right', framealpha=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This effect is even more pronounced when we plot the mean abolute error (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splits.plot('split', ['mae_train', 'mae_val'], kind='bar')\n",
    "plt.title(f'Performance of {type(model).__name__}\\nwith {len(splits)} different data splits')\n",
    "plt.ylabel('MAE in $\\mathrm{C}_\\mathrm{p}$ (J / mol K)')\n",
    "plt.xlabel('Split #')\n",
    "plt.legend(loc='lower right', framealpha=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, typically the average value of all the scores are reported, as this gives a much more accurate estimate of how well the model actually performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_r2_val = df_splits['r2_val'].mean()\n",
    "avg_mae_val = df_splits['mae_val'].mean()\n",
    "\n",
    "print(f'Average validation r2: {avg_r2_val:0.4f}')\n",
    "print(f'Average validation MAE: {avg_mae_val:0.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
